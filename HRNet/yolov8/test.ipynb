{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5cce86-e576-4a21-b4a6-68eb61d1075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.144 ğŸš€ Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (Quadro RTX 8000, 48586MiB)\n",
      "Setup complete âœ… (80 CPUs, 376.5 GB RAM, 855.0/937.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc727bea-d451-4816-b59f-549b5aa9bd29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.144 ğŸš€ Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (Quadro RTX 8000, 48586MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=bsf1.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-pose.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train29, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/pose/train29, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml kpt_shape=[17, 3] with kpt_shape=[2, 3]\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    823429  ultralytics.nn.modules.head.Pose             [1, [2, 3], [64, 128, 256]]   \n",
      "YOLOv8n-pose summary: 144 layers, 3,082,965 parameters, 3,082,949 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 361/397 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.2Â±0.0 ms, read: 3238.9Â±391.8 MB/s, size: 4231.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/hope/R&D_Pro/HRNet/data/bsf2023/labels/train... 1246 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1246/1246 [00:01<00:00, 1187.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/hope/R&D_Pro/HRNet/data/bsf2023/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.0 ms, read: 3031.3Â±425.1 MB/s, size: 4168.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/hope/R&D_Pro/HRNet/data/bsf2023/labels/val... 140 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140/140 [00:00<00:00, 1459.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/hope/R&D_Pro/HRNet/data/bsf2023/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/pose/train29/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/pose/train29\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      2.05G     0.9522      1.863     0.6067      1.005      1.071         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [03:08<00:00,  2.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.999      0.993      0.995      0.798      0.991      0.986      0.992      0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      2.13G     0.8737     0.7422     0.4784     0.6748     0.9983         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:55<00:00,  2.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.889      0.973      0.958      0.784      0.895      0.975      0.969      0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      2.13G     0.8989     0.5106     0.4259     0.6714      1.033         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:57<00:00,  2.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140       0.99      0.979      0.995      0.798       0.99      0.979      0.995      0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      2.13G     0.8582     0.4384     0.3802     0.6349      1.022         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [03:00<00:00,  2.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.973      0.993      0.993      0.817      0.966      0.986       0.99      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      2.13G     0.8275      0.338      0.322     0.6006     0.9939         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:52<00:00,  2.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.996          1      0.995      0.853      0.982      0.986      0.981       0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      2.13G     0.7894     0.2796     0.2602     0.5653     0.9936         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [03:10<00:00,  2.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.993      0.993      0.995      0.837      0.993      0.993      0.995      0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      2.13G     0.7793     0.2876     0.2226     0.5653     0.9893         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:59<00:00,  2.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.996          1      0.995       0.86      0.996          1      0.995      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      2.13G     0.7508     0.2315     0.1734     0.5354     0.9785         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:54<00:00,  2.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.999          1      0.995      0.853      0.999          1      0.995      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      2.13G     0.7475     0.2048     0.1506     0.5298     0.9884         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:57<00:00,  2.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.993          1      0.995      0.866      0.993          1      0.995      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      2.13G     0.7101     0.1846     0.1498     0.5001     0.9632         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:54<00:00,  2.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.985          1      0.995      0.884      0.985          1      0.995      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      2.13G     0.5835     0.1475    0.05152      0.399     0.8845         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:58<00:00,  2.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.998          1      0.995      0.884      0.998          1      0.995      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      2.13G     0.5821     0.1389    0.05016     0.3899     0.8823         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:57<00:00,  2.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.999          1      0.995      0.867      0.977      0.979      0.966      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      2.13G     0.5707     0.1319    0.04723     0.3843     0.8746         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:57<00:00,  2.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.999          1      0.995      0.896      0.999          1      0.995      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      2.13G     0.5189    0.08132    0.04136     0.3478     0.8568         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:57<00:00,  2.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.999          1      0.995      0.913      0.999          1      0.995      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      2.13G     0.5012     0.0863    0.04187     0.3296     0.8491         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:57<00:00,  2.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.999          1      0.995      0.917      0.999          1      0.995      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      2.13G     0.4917    0.07895    0.04227     0.3154     0.8441         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:56<00:00,  2.26s/it]\n",
      "      18/20      2.13G     0.4813    0.06633    0.04429     0.3049     0.8508         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [03:06<00:00,  2.39s/it] | 4/5 [00:18<00:04,  4.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140      0.999          1      0.995      0.916      0.999          1      0.995      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      2.13G     0.4645    0.05937    0.04193     0.2933     0.8421         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:55<00:00,  2.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17<00:00,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140          1          1      0.995      0.921          1          1      0.995      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      2.13G      0.448    0.05996    0.04548      0.282     0.8441         16        640:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 43/78 [01:37<01:17,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/pose/train29\u001b[0m\n",
      "Ultralytics 8.3.144 ğŸš€ Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (Quadro RTX 8000, 48586MiB)\n",
      "YOLOv8n-pose summary (fused): 81 layers, 3,077,669 parameters, 0 gradients, 8.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3296.7Â±1275.2 MB/s, size: 4246.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/hope/R&D_Pro/HRNet/data/bsf2023/labels/val.cache... 140 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140/140 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:20<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        140        140          1          1      0.995      0.928          1          1      0.995      0.995\n",
      "Speed: 0.4ms preprocess, 2.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/pose/train292\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'PosixPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 3. æ‰“å°è®­ç»ƒè¿‡ç¨‹æŒ‡æ ‡\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m  \u001b[38;5;66;03m# è‡ªåŠ¨è·å–expç›®å½•\u001b[39;00m\n\u001b[1;32m     23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n\u001b[1;32m     24\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr/pg0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/box_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/kpt_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics/mAP_0.5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics/mAP_0.5:kpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'PosixPath' and 'str'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "\n",
    "# 1. è®­ç»ƒ\n",
    "model = YOLO(\"yolov8n-pose.pt\")\n",
    "\n",
    "# Load a mode\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=\"bsf1.yaml\",\n",
    "    epochs=20,\n",
    "    imgsz=640,\n",
    "    device=0,          # æ”¹ä¸ºä½ çš„GPU\n",
    "    verbose=True,\n",
    "    workers=0\n",
    ")\n",
    "\n",
    "# 2. éªŒè¯ï¼ˆç›´æ¥è°ƒç”¨ï¼Œæ–¹ä¾¿çœ‹åˆ†æ•°ï¼‰\n",
    "metrics = model.val()\n",
    "\n",
    "# 3. æ‰“å°è®­ç»ƒè¿‡ç¨‹æŒ‡æ ‡\n",
    "csv_path = model.trainer.save_dir + \"/results.csv\"  # è‡ªåŠ¨è·å–expç›®å½•\n",
    "df = pd.read_csv(csv_path)\n",
    "cols = [\"epoch\", \"lr/pg0\", \"train/box_loss\", \"train/kpt_loss\", \"metrics/mAP_0.5\", \"metrics/mAP_0.5:kpt\"]\n",
    "print(\"{:^6} | {:^10} | {:^12} | {:^12} | {:^12} | {:^15}\".format(\"Epoch\", \"LR\", \"Box Loss\", \"Kpt Loss\", \"mAP@0.5\", \"mAP@0.5:kpt\"))\n",
    "print(\"-\" * 80)\n",
    "for _, row in df.iterrows():\n",
    "    print(\"{:^6} | {:^10.6f} | {:^12.4f} | {:^12.4f} | {:^12.4f} | {:^15.4f}\".format(\n",
    "        int(row[\"epoch\"]), row[\"lr/pg0\"], row[\"train/box_loss\"], row[\"train/kpt_loss\"], row[\"metrics/mAP_0.5\"], row[\"metrics/mAP_0.5:kpt\"]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08959ad-c2c5-4281-8867-2de136cd71c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epoch     time  train/box_loss  train/pose_loss  train/kobj_loss  \\\n",
      "0      1  208.706         0.95224          1.86289          0.60673   \n",
      "1      2  404.037         0.87374          0.74219          0.47842   \n",
      "2      3  600.886         0.89892          0.51060          0.42595   \n",
      "3      4  800.992         0.85824          0.43843          0.38023   \n",
      "4      5  991.784         0.82746          0.33803          0.32199   \n",
      "\n",
      "   train/cls_loss  train/dfl_loss  metrics/precision(B)  metrics/recall(B)  \\\n",
      "0         1.00541         1.07146               0.99856            0.99286   \n",
      "1         0.67484         0.99826               0.88904            0.97292   \n",
      "2         0.67138         1.03262               0.98979            0.97857   \n",
      "3         0.63488         1.02227               0.97253            0.99286   \n",
      "4         0.60060         0.99391               0.99589            1.00000   \n",
      "\n",
      "   metrics/mAP50(B)  ...  metrics/mAP50(P)  metrics/mAP50-95(P)  val/box_loss  \\\n",
      "0           0.99500  ...           0.99178              0.79320       0.79641   \n",
      "1           0.95838  ...           0.96851              0.86215       0.72236   \n",
      "2           0.99458  ...           0.99458              0.86824       0.74342   \n",
      "3           0.99340  ...           0.98993              0.91239       0.71519   \n",
      "4           0.99500  ...           0.98073              0.94987       0.62006   \n",
      "\n",
      "   val/pose_loss  val/kobj_loss  val/cls_loss  val/dfl_loss    lr/pg0  \\\n",
      "0        0.89368        0.52241       0.62029       0.96316  0.000658   \n",
      "1        0.52067        0.25318       0.71213       0.90752  0.001259   \n",
      "2        0.49730        0.10446       0.77818       0.94088  0.001794   \n",
      "3        0.37125        0.07369       0.68361       0.90149  0.001703   \n",
      "4        0.26049        0.05828       0.51935       0.87308  0.001604   \n",
      "\n",
      "     lr/pg1    lr/pg2  \n",
      "0  0.000658  0.000658  \n",
      "1  0.001259  0.001259  \n",
      "2  0.001794  0.001794  \n",
      "3  0.001703  0.001703  \n",
      "4  0.001604  0.001604  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_path = model.trainer.save_dir / \"results.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00788517-d2e5-4d0f-848b-11a117ab75a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.txté‡Œå®é™…ä¸å­˜åœ¨çš„å›¾ç‰‡: []\n",
      "å…±è®¡: 0\n",
      "val.txté‡Œå®é™…ä¸å­˜åœ¨çš„å›¾ç‰‡: []\n",
      "å…±è®¡: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "img_root = '/home/hope/R&D_Pro/HRNet/data/bsf2023'\n",
    "train_txt = os.path.join(img_root, 'train.txt')\n",
    "\n",
    "with open(train_txt) as f:\n",
    "    lines = [l.strip() for l in f.readlines()]\n",
    "bad = [l for l in lines if not os.path.isfile(os.path.join(img_root, l))]\n",
    "print('train.txté‡Œå®é™…ä¸å­˜åœ¨çš„å›¾ç‰‡:', bad)\n",
    "print('å…±è®¡:', len(bad))\n",
    "\n",
    "# å†æŸ¥ä¸€éval\n",
    "val_txt = os.path.join(img_root, 'val.txt')\n",
    "with open(val_txt) as f:\n",
    "    vlines = [l.strip() for l in f.readlines()]\n",
    "vbad = [l for l in vlines if not os.path.isfile(os.path.join(img_root, l))]\n",
    "print('val.txté‡Œå®é™…ä¸å­˜åœ¨çš„å›¾ç‰‡:', vbad)\n",
    "print('å…±è®¡:', len(vbad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b8d0dd-b66c-4177-ba92-024ebba84ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] æ²¡æœ‰æ ‡ç­¾çš„å›¾ç‰‡: set()\n",
      "[train] æ²¡æœ‰å›¾ç‰‡çš„æ ‡ç­¾: set()\n",
      "[val] æ²¡æœ‰æ ‡ç­¾çš„å›¾ç‰‡: set()\n",
      "[val] æ²¡æœ‰å›¾ç‰‡çš„æ ‡ç­¾: set()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root = '/home/hope/R&D_Pro/HRNet/data/bsf2023'\n",
    "for subset in ['train', 'val']:\n",
    "    img_dir = os.path.join(root, 'images', subset)\n",
    "    label_dir = os.path.join(root, 'labels', subset)\n",
    "    imgs = set([os.path.splitext(f)[0] for f in os.listdir(img_dir) if f.endswith('.jpg')])\n",
    "    labels = set([os.path.splitext(f)[0] for f in os.listdir(label_dir) if f.endswith('.txt')])\n",
    "    print(f'[{subset}] æ²¡æœ‰æ ‡ç­¾çš„å›¾ç‰‡:', imgs - labels)\n",
    "    print(f'[{subset}] æ²¡æœ‰å›¾ç‰‡çš„æ ‡ç­¾:', labels - imgs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-2024.02-yolo]",
   "language": "python",
   "name": "conda-env-.conda-2024.02-yolo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
